import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from collections import Counter
import math
import inspect
import concurrent.futures
from urllib.parse import urlparse

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –°–¢–ò–õ–ò
# ==========================================
st.set_page_config(
    layout="wide", 
    page_title="–ì–ê–† PRO: –ê–Ω–∞–ª–∏–∑", 
    page_icon="üìä",
    initial_sidebar_state="collapsed"
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø–æ—Ç–µ—Ä—è–Ω—ã
DEFAULT_EXCLUDE = ["yandex.ru", "avito.ru", "ozon.ru", "wildberries.ru", "youtube.com", "dzen.ru", "hh.ru", "t.me"]
DEFAULT_STOPS = ["—Ä—É–±–ª–µ–π", "—Ä—É–±", "–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "—à—Ç", "—Å–º", "–º–º", "–∫–≥", "–∫–≤", "–º2", "—Å—Ç—Ä", "—É–ª"]

# –ü–æ–ª–Ω—ã–π CSS —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
st.markdown("""
    <style>
        /* –°–ë–†–û–° –°–¢–ò–õ–ï–ô STREAMLIT */
        .stApp {
            background: linear-gradient(135deg, #E6F3FF 0%, #F0F9FF 50%, #E6F7FF 100%) !important;
            color: #262730 !important;
            font-family: 'Inter', sans-serif !important;
        }
        
        /* –û–°–ù–û–í–ù–´–ï –≠–õ–ï–ú–ï–ù–¢–´ */
        h1, h2, h3, h4, h5, h6 {
            color: #1890ff !important;
            font-weight: 600 !important;
            font-family: 'Inter', sans-serif !important;
        }
        
        p, div, span, label {
            color: #262730 !important;
            font-family: 'Inter', sans-serif !important;
        }
        
        /* –ö–û–ù–¢–ï–ô–ù–ï–†–´ */
        .main .block-container {
            background: transparent !important;
            padding-top: 2rem !important;
        }
        
        /* –ì–õ–ê–í–ù–´–ô –ë–õ–û–ö –í–í–û–î–ê */
        .main-input-container {
            background: linear-gradient(135deg, #ffffff 0%, #f8fcff 100%) !important;
            padding: 25px !important;
            border-radius: 15px !important;
            border: 1px solid #e1f0ff !important;
            margin-bottom: 25px !important;
            box-shadow: 0 4px 12px rgba(0, 120, 215, 0.08) !important;
        }
        
        /* –ö–ù–û–ü–ö–ò */
        .stButton button {
            background: linear-gradient(135deg, #1890ff 0%, #096dd9 100%) !important;
            color: white !important;
            font-weight: 600 !important;
            border-radius: 10px !important;
            height: 55px !important;
            width: 100% !important;
            border: none !important;
            font-size: 16px !important;
            transition: all 0.3s ease !important;
            box-shadow: 0 4px 12px rgba(24, 144, 255, 0.3) !important;
        }
        
        .stButton button:hover {
            background: linear-gradient(135deg, #096dd9 0%, #0050b3 100%) !important;
            transform: translateY(-2px) !important;
            box-shadow: 0 6px 16px rgba(24, 144, 255, 0.4) !important;
            color: white !important;
        }
        
        /* –¢–ï–ö–°–¢–û–í–´–ï –ü–û–õ–Ø */
        .stTextInput input, .stTextArea textarea {
            background-color: #ffffff !important;
            color: #262730 !important;
            border: 1px solid #bae7ff !important;
            border-radius: 8px !important;
            padding: 10px !important;
        }
        
        .stTextInput input:focus, .stTextArea textarea:focus {
            border-color: #1890ff !important;
            box-shadow: 0 0 0 2px rgba(24, 144, 255, 0.2) !important;
        }
        
        /* –†–ê–î–ò–û –ö–ù–û–ü–ö–ò */
        .stRadio > div {
            background-color: #ffffff !important;
            padding: 15px !important;
            border-radius: 10px !important;
            border: 1px solid #e1f0ff !important;
            margin-bottom: 10px !important;
        }
        
        .stRadio label {
            color: #262730 !important;
            font-weight: 500 !important;
        }
        
        /* –°–ï–õ–ï–ö–¢–´ */
        .stSelectbox select {
            background-color: #ffffff !important;
            color: #262730 !important;
            border: 1px solid #bae7ff !important;
            border-radius: 8px !important;
        }
        
        /* –ß–ï–ö–ë–û–ö–°–´ */
        .stCheckbox {
            color: #262730 !important;
        }
        
        .stCheckbox > label {
            color: #096dd9 !important;
            font-weight: 500 !important;
        }
        
        /* EXPANDER */
        .streamlit-expanderHeader {
            background: linear-gradient(135deg, #f0f9ff 0%, #e6f7ff 100%) !important;
            color: #096dd9 !important;
            font-weight: 600 !important;
            border-radius: 10px !important;
            border: 1px solid #bae7ff !important;
            padding: 15px !important;
        }
        
        .streamlit-expanderContent {
            background-color: #ffffff !important;
            border-radius: 0 0 10px 10px !important;
            border: 1px solid #e1f0ff !important;
            border-top: none !important;
        }
        
        /* –ü–†–û–ì–†–ï–°–° –ë–ê–† */
        .stProgress > div > div > div {
            background: linear-gradient(90deg, #1890ff 0%, #36cfc9 100%) !important;
        }
        
        /* –¢–ê–ë–õ–ò–¶–´ */
        .dataframe {
            border-radius: 10px !important;
            box-shadow: 0 4px 12px rgba(0, 120, 215, 0.1) !important;
        }
        
        /* DIVIDER */
        hr {
            border-color: #e1f0ff !important;
            margin: 2rem 0 !important;
        }
        
        /* SPINNER */
        .stSpinner > div {
            border-color: #1890ff !important;
        }
        
        /* ALERTS */
        .stAlert {
            border-radius: 10px !important;
            border: 1px solid !important;
        }
        
        .stAlert [data-testid="stMarkdownContainer"] {
            color: inherit !important;
        }
        
        /* LABELS –î–õ–Ø –í–°–ï–• –≠–õ–ï–ú–ï–ù–¢–û–í */
        .stTextInput label, .stTextArea label, .stSelectbox label, .stNumberInput label {
            color: #096dd9 !important;
            font-weight: 600 !important;
            font-size: 14px !important;
        }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# ==========================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: 
        return True
    
    st.markdown("""
        <div style='
            display: flex; 
            justify-content: center; 
            align-items: center; 
            min-height: 80vh;
        '>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.markdown("""
            <div style='
                background: linear-gradient(135deg, #ffffff 0%, #f8fcff 100%); 
                padding: 40px; 
                border-radius: 20px; 
                border: 1px solid #e1f0ff; 
                box-shadow: 0 8px 25px rgba(0, 120, 215, 0.15);
                text-align: center;
            '>
                <h2 style='color: #1890ff; margin-bottom: 30px;'>üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è</h2>
        """, unsafe_allow_html=True)
        
        pwd = st.text_input("–ü–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞", type="password", key="auth_password")
        
        if st.button("–í–æ–π—Ç–∏", key="auth_btn"):
            if pwd == "admin123":
                st.session_state["password_correct"] = True
                st.rerun()
            else: 
                st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    return False

if not check_password(): 
    st.stop()

# ==========================================
# 3. –ë–≠–ö–ï–ù–î (–õ–û–ì–ò–ö–ê)
# ==========================================

# --- –ü–∞—Ç—á NLP ---
try:
    if not hasattr(inspect, 'getargspec'):
        def getargspec(func):
            spec = inspect.getfullargspec(func)
            return spec.args, spec.varargs, spec.varkw, spec.defaults
        inspect.getargspec = getargspec
    import pymorphy2
    morph = pymorphy2.MorphAnalyzer()
    USE_NLP = True
except:
    morph = None
    USE_NLP = False

# --- –ü–æ–∏—Å–∫ ---
try:
    from googlesearch import search
    USE_SEARCH = True
except:
    USE_SEARCH = False

# --- –ü–∞—Ä—Å–∏–Ω–≥ ---
def get_domain(url):
    try: 
        return urlparse(url).netloc
    except: 
        return url

def parse_page(url, settings):
    headers = {'User-Agent': settings['ua']}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code != 200: 
            return None
        
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # –ú–µ—Ç–∞-—Ç–µ–≥–∏
        title = soup.title.string if soup.title else ""
        desc = ""
        meta_desc = soup.find("meta", attrs={"name": "description"})
        if meta_desc: 
            desc = meta_desc.get("content", "")
        h1 = soup.find("h1").get_text(strip=True) if soup.find("h1") else ""
        
        # –û—á–∏—Å—Ç–∫–∞
        if settings['noindex']:
            for t in soup.find_all(['noindex', 'script', 'style']): 
                t.decompose()
        else:
            for t in soup(['script', 'style']): 
                t.decompose()
            
        # –ê–Ω–∫–æ—Ä—ã
        anchors_list = []
        for a in soup.find_all('a'):
            txt = a.get_text(strip=True)
            if txt: 
                anchors_list.append(txt)
        anchor_text = " ".join(anchors_list)
        
        # –¢–µ–∫—Å—Ç (Body)
        body_text = soup.get_text(separator=' ')
        if settings['alt_title']:
            for img in soup.find_all('img', alt=True): 
                body_text += " " + img['alt']
            
        return {
            'url': url,
            'domain': get_domain(url),
            'title': title,
            'desc': desc,
            'h1': h1,
            'body_text': body_text,
            'anchor_text': anchor_text,
            'status': 200
        }
    except:
        return None

def process_lemmas(text, settings):
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    pattern = r'[–∞-—è–ê-–Ø—ë–Å0-9a-zA-Z]+' if settings['numbers'] else r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+'
    words = re.findall(pattern, text)
    
    lemmas = []
    forms_map = {} # –ª–µ–º–º–∞ -> —Å–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º
    
    stops = set(w.lower() for w in settings['custom_stops'])
    
    for w in words:
        w_lower = w.lower()
        if len(w) < 2 or w_lower in stops: 
            continue
        
        lemma = w_lower
        if USE_NLP:
            p = morph.parse(w_lower)[0]
            if settings['std_stops'] and ('PREP' in p.tag or 'CONJ' in p.tag or 'PRCL' in p.tag):
                continue
            lemma = p.normal_form
            
        lemmas.append(lemma)
        
        if lemma not in forms_map: 
            forms_map[lemma] = set()
        forms_map[lemma].add(w_lower)
        
    return lemmas, forms_map

# ==========================================
# 4. –ò–ù–¢–ï–†–§–ï–ô–°
# ==========================================

st.title("üéØ –ì–ê–† PRO: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")

# –ì–õ–ê–í–ù–´–ô –ë–õ–û–ö –í–í–û–î–ê
with st.container():
    st.markdown('<div class="main-input-container">', unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    with c1:
        my_url = st.text_input(
            "–í–∞—à URL (–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", 
            placeholder="https://mysite.ru/catalog/page",
            key="my_url"
        )
    with c2:
        query = st.text_input(
            "–ü–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å", 
            placeholder="–∫—É–ø–∏—Ç—å —Ç–æ–≤–∞—Ä –º–æ—Å–∫–≤–∞",
            key="query"
        )
    st.markdown('</div>', unsafe_allow_html=True)

# –ò–°–¢–û–ß–ù–ò–ö –ö–û–ù–ö–£–†–ï–ù–¢–û–í
st.subheader("üìä –ò—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
source_mode = st.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫:",
    ["Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)", "–†—É—á–Ω–æ–π —Å–ø–∏—Å–æ–∫"], 
    horizontal=True, 
    key="source_mode"
)

competitors_final = []

if source_mode == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
    c_s1, c_s2 = st.columns([1, 3])
    with c_s1:
        top_count = st.selectbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–ü:", [5, 10, 20], index=1, key="top_count")
    with c_s2:
        exclude_domains = st.text_input(
            "–ò—Å–∫–ª—é—á–∏—Ç—å –¥–æ–º–µ–Ω—ã (—á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª)", 
            " ".join(DEFAULT_EXCLUDE),
            key="exclude_domains"
        )
else:
    manual_urls = st.text_area(
        "–°–ø–∏—Å–æ–∫ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", 
        height=150,
        key="manual_urls",
        placeholder="https://competitor1.com\nhttps://competitor2.com\nhttps://competitor3.com"
    )

# –ù–ê–°–¢–†–û–ô–ö–ò
with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞", expanded=True):
    col_set1, col_set2, col_set3 = st.columns(3)
    with col_set1:
        s_noindex = st.checkbox("–ò—Å–∫–ª—é—á–∞—Ç—å noindex", True, key="s_noindex")
        s_alt = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å Alt/Title", False, key="s_alt")
    with col_set2:
        s_norm = st.checkbox("–ù–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–ª–∏–Ω–µ", True, key="s_norm")
        s_num = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å —á–∏—Å–ª–∞", False, key="s_num")
    with col_set3:
        s_std_stops = st.checkbox("–£–±–∏—Ä–∞—Ç—å –ø—Ä–µ–¥–ª–æ–≥–∏", True, key="s_std_stops")
    
    custom_stops_text = st.text_area(
        "–°—Ç–æ–ø-—Å–ª–æ–≤–∞ (–∫–∞–∂–¥–æ–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", 
        "\n".join(DEFAULT_STOPS), 
        height=100,
        key="custom_stops"
    )
    user_agent = st.text_input(
        "User-Agent", 
        "Mozilla/5.0 (compatible; Hybrid-Analyzer/1.0;)",
        key="user_agent"
    )

# –ö–ù–û–ü–ö–ê –ó–ê–ü–£–°–ö–ê
if st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨ –ê–ù–ê–õ–ò–ó", key="analyze_btn"):
    if not my_url:
        st.error("‚ùå –í—ã –Ω–µ –≤–≤–µ–ª–∏ URL –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞!")
        st.stop()
        
    settings = {
        'noindex': s_noindex, 
        'alt_title': s_alt, 
        'numbers': s_num,
        'norm': s_norm, 
        'std_stops': s_std_stops,
        'custom_stops': custom_stops_text.split(), 
        'ua': user_agent
    }
    
    # 1. –°–±–æ—Ä URL
    target_urls = []
    if source_mode == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
        if not query:
            st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å!")
            st.stop()
        try:
            excl = exclude_domains.split()
            found = search(query, num_results=top_count*2, lang="ru")
            cnt = 0
            for u in found:
                if my_url in u: 
                    continue
                if any(x in u for x in excl): 
                    continue
                target_urls.append(u)
                cnt += 1
                if cnt >= top_count: 
                    break
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            st.stop()
    else:
        target_urls = [u.strip() for u in manual_urls.split('\n') if u.strip()]
        
    if not target_urls:
        st.error("‚ùå –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç!")
        st.stop()
        
    # 2. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    all_pages_data = []
    
    # –°–Ω–∞—á–∞–ª–∞ –º–æ–π —Å–∞–π—Ç
    with st.spinner("üîç –ê–Ω–∞–ª–∏–∑ –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞..."):
        my_page = parse_page(my_url, settings)
        if not my_page:
            st.error("‚ùå –í–∞—à —Å–∞–π—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            st.stop()
            
    # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
    progress_bar = st.progress(0)
    comp_pages = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(parse_page, u, settings): u for u in target_urls}
        done = 0
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: 
                comp_pages.append(res)
            done += 1
            progress_bar.progress(done / len(target_urls))
            
    if len(comp_pages) < 2:
        st.error("‚ùå –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞).")
        st.stop()
        
    # ==========================================
    # 5. –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê –ò –¢–ê–ë–õ–ò–¶–´
    # ==========================================
    
    # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
    my_body_lemmas, my_body_forms = process_lemmas(my_page['body_text'], settings)
    my_anchor_lemmas, my_anchor_forms = process_lemmas(my_page['anchor_text'], settings)
    
    comp_stats = [] # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ª–µ–º–º–∞–º–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    for p in comp_pages:
        bl, _ = process_lemmas(p['body_text'], settings)
        al, _ = process_lemmas(p['anchor_text'], settings)
        comp_stats.append({'body': bl, 'anchor': al, 'len': len(bl)})
        
    # –ù–æ—Ä–º–∏—Ä–æ–≤–∫–∞
    avg_len = np.mean([c['len'] for c in comp_stats])
    my_len = len(my_body_lemmas)
    norm_k = (my_len / avg_len) if (settings['norm'] and avg_len > 0) else 1.0
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–°–ª–æ–≤–∞—Ä—å)
    vocab = set(my_body_lemmas)
    for c in comp_stats: 
        vocab.update(c['body'])
    vocab = sorted(list(vocab))
    
    # –°–±–æ—Ä–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ)
    rows = []
    
    # –î–ª—è IDF
    N = len(comp_stats)
    doc_freqs = Counter()
    for c in comp_stats:
        for w in set(c['body']): 
            doc_freqs[w] += 1
    
    for word in vocab:
        # –£ –º–µ–Ω—è
        my_body_tf = my_body_lemmas.count(word)
        my_anchor_tf = my_anchor_lemmas.count(word)
        
        # –£ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–º–∞—Å—Å–∏–≤—ã)
        c_body_tfs = [c['body'].count(word) for c in comp_stats]
        c_anchor_tfs = [c['anchor'].count(word) for c in comp_stats]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        median_body = np.median(c_body_tfs)
        median_anchor = np.median(c_anchor_tfs)
        max_spam = np.max(c_body_tfs)
        
        # –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏)
        target_body = int(median_body * 1.3 * norm_k)
        target_anchor = int(median_anchor * 1.3 * norm_k)
        
        diff_body = target_body - my_body_tf
        diff_anchor = target_anchor - my_anchor_tf
        
        # IDF
        df = doc_freqs[word]
        idf = math.log((N / (df if df>0 else 1)) + 1)
        
        # –§–∏–ª—å—Ç—Ä –º—É—Å–æ—Ä–∞ (–µ—Å–ª–∏ —Å–ª–æ–≤–æ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —É –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ–∑–Ω–∞—á–∏–º–æ)
        if (median_body > 0.5 or my_body_tf > 0):
            # –°–±–æ—Ä —Å–ª–æ–≤–æ—Ñ–æ—Ä–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            forms = []
            if word in my_body_forms: 
                forms.extend(my_body_forms[word])
            forms_str = ", ".join(list(set(forms))[:3])
            
            rows.append({
                "–°–ª–æ–≤–æ": word,
                "–°–ª–æ–≤–æ—Ñ–æ—Ä–º—ã": forms_str,
                "–ü–æ–≤—Ç–æ—Ä—ã —É –≤–∞—Å": my_body_tf,
                "–û–±—â–µ–µ –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                
                "–¢–µ–≥ A —É –≤–∞—Å": my_anchor_tf,
                "–¢–µ–≥ A —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_anchor,
                "–¢–µ–≥ A –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_anchor,
                
                "–¢–µ–∫—Å—Ç —É –≤–∞—Å": my_body_tf,
                "–¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_body,
                "–¢–µ–∫—Å—Ç –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                
                "–ü–µ—Ä–µ—Å–ø–∞–º": int(max_spam * norm_k),
                "–ü–µ—Ä–µ—Å–ø–∞–º*IDF": round(max_spam * norm_k * idf, 1),
                
                "diff_abs": abs(diff_body) # –°–∫—Ä—ã—Ç–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            })
            
    df_main = pd.DataFrame(rows)
    
    # --- –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
    
    st.divider()
    
    # 1. –¢–ê–ë–õ–ò–¶–ê: –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ì–õ–£–ë–ò–ù–ï
    st.markdown('<div class="table-header">üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ</div>', unsafe_allow_html=True)
    if not df_main.empty:
        df_main = df_main.sort_values(by="diff_abs", ascending=False)
        
        # –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è (–ø–æ–¥—Å–≤–µ—Ç–∫–∞)
        def color_diff(val):
            if val > 0: 
                return 'background-color: #e6fffb; color: #006d75'
            if val < 0: 
                return 'background-color: #fff2e8; color: #ad4e00'
            return ''
            
        st.dataframe(
            df_main.style.map(color_diff, subset=['–û–±—â–µ–µ –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å', '–¢–µ–≥ A –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å', '–¢–µ–∫—Å—Ç –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å']),
            column_config={"diff_abs": None},
            use_container_width=True,
            height=600
        )
    else:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")

    # 2. –¢–ê–ë–õ–ò–¶–ê: –ú–ï–¢–ê-–¢–ï–ì–ò
    st.markdown('<div class="table-header">üîç –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞-—Ç–µ–≥–∞–º</div>', unsafe_allow_html=True)
    meta_data = []
    # –ú–æ–π —Å–∞–π—Ç
    meta_data.append({
        "–¢–∏–ø": "–í–∞—à —Å–∞–π—Ç",
        "Title": my_page['title'],
        "Description": my_page['desc'],
        "H1": my_page['h1']
    })
    # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã (–ø–µ—Ä–≤—ã–µ 5)
    for i, p in enumerate(comp_pages[:5]):
        meta_data.append({
            "–¢–∏–ø": f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç {i+1} ({p['domain']})",
            "Title": p['title'],
            "Description": p['desc'],
            "H1": p['h1']
        })
    st.dataframe(pd.DataFrame(meta_data), use_container_width=True)

    # 3. –¢–ê–ë–õ–ò–¶–ê: –¢–û–ü –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò –î–û–ö–£–ú–ï–ù–¢–û–í
    st.markdown('<div class="table-header">üèÜ –¢–û–ü —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</div>', unsafe_allow_html=True)
    top_rows = []
    for i, p in enumerate(comp_pages):
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–∫–æ–ª-–≤–æ —Å–ª–æ–≤ –∏–∑ –æ–±—â–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è)
        p_lemmas, _ = process_lemmas(p['body_text'], settings)
        coverage = len(set(p_lemmas).intersection(vocab))
        
        top_rows.append({
            "–î–æ–º–µ–Ω": p['domain'],
            "–ü–æ–∑–∏—Ü–∏—è": i+1,
            "URL": p['url'],
            "–®–∏—Ä–∏–Ω–∞ (–û—Ö–≤–∞—Ç)": coverage,
            "–ì–ª—É–±–∏–Ω–∞ (–í—Å–µ–≥–æ —Å–ª–æ–≤)": len(p_lemmas)
        })
    st.dataframe(pd.DataFrame(top_rows), use_container_width=True)
