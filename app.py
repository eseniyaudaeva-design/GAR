import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from collections import Counter
import math
import inspect
import concurrent.futures
from urllib.parse import urlparse

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –°–¢–ò–õ–ò
# ==========================================
st.set_page_config(layout="wide", page_title="–ì–ê–† PRO: –ê–Ω–∞–ª–∏–∑", page_icon="üìä")

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        
        /* –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∏–ª–∏ */
        .main {
            background: linear-gradient(135deg, #E6F3FF 0%, #F0F9FF 50%, #E6F7FF 100%);
        }
        
        html, body, [class*="css"] { 
            font-family: 'Inter', sans-serif;
            background: #f8fcff;
        }
        
        /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä—Ö–Ω–µ–π –ø–∞–Ω–µ–ª–∏ –≤–≤–æ–¥–∞ */
        .main-input-container {
            background: linear-gradient(135deg, #ffffff 0%, #f8fcff 100%);
            padding: 25px;
            border-radius: 15px;
            border: 1px solid #e1f0ff;
            margin-bottom: 25px;
            box-shadow: 0 4px 12px rgba(0, 120, 215, 0.08);
        }
        
        /* –ö–Ω–æ–ø–∫–∞ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º */
        .stButton button {
            background: linear-gradient(135deg, #1890ff 0%, #096dd9 100%);
            color: white;
            font-weight: 600;
            border-radius: 10px;
            height: 55px;
            width: 100%;
            border: none;
            font-size: 16px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(24, 144, 255, 0.3);
        }
        
        .stButton button:hover {
            background: linear-gradient(135deg, #096dd9 0%, #0050b3 100%);
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(24, 144, 255, 0.4);
        }
        
        /* –ó–∞–≥–æ–ª–æ–≤–∫–∏ */
        h1 {
            color: #1890ff;
            font-weight: 700;
            margin-bottom: 20px;
        }
        
        h2, h3 {
            color: #096dd9;
            font-weight: 600;
        }
        
        /* –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü */
        .table-header { 
            font-size: 20px; 
            font-weight: 600; 
            margin-top: 35px; 
            margin-bottom: 15px; 
            color: #096dd9;
            padding: 10px 0;
            border-bottom: 2px solid #e6f7ff;
        }
        
        /* –†–∞–¥–∏–æ –∫–Ω–æ–ø–∫–∏ */
        .stRadio > div {
            background: white;
            padding: 15px;
            border-radius: 10px;
            border: 1px solid #e1f0ff;
        }
        
        /* Expander */
        .streamlit-expanderHeader {
            background: linear-gradient(135deg, #f0f9ff 0%, #e6f7ff 100%);
            color: #096dd9;
            font-weight: 600;
            border-radius: 10px;
            border: 1px solid #bae7ff;
        }
        
        /* –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä */
        .stProgress > div > div > div {
            background: linear-gradient(90deg, #1890ff 0%, #36cfc9 100%);
        }
        
        /* –¢–∞–±–ª–∏—Ü—ã */
        .dataframe {
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0, 120, 215, 0.1);
        }
        
        /* –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è */
        .stTextInput input, .stTextArea textarea {
            border: 1px solid #bae7ff;
            border-radius: 8px;
            padding: 12px;
            background: #fafdff;
        }
        
        .stTextInput input:focus, .stTextArea textarea:focus {
            border-color: #1890ff;
            box-shadow: 0 0 0 2px rgba(24, 144, 255, 0.2);
        }
        
        /* –°–µ–ª–µ–∫—Ç—ã */
        .stSelectbox select {
            border: 1px solid #bae7ff;
            border-radius: 8px;
            background: #fafdff;
        }
        
        /* –ß–µ–∫–±–æ–∫—Å—ã */
        .stCheckbox > label {
            color: #096dd9;
            font-weight: 500;
        }
        
        /* –£—Å–ø–µ—à–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è */
        .stAlert {
            border-radius: 10px;
        }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# ==========================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: return True
    
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.markdown("""
            <div style='text-align: center; padding: 30px; background: linear-gradient(135deg, #ffffff 0%, #f8fcff 100%); 
                     border-radius: 15px; border: 1px solid #e1f0ff; box-shadow: 0 4px 12px rgba(0, 120, 215, 0.08);'>
                <h2 style='color: #1890ff; margin-bottom: 30px;'>üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è</h2>
        """, unsafe_allow_html=True)
        pwd = st.text_input("–ü–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞", type="password")
        if st.button("–í–æ–π—Ç–∏", key="auth_btn"):
            if pwd == "admin123":
                st.session_state["password_correct"] = True
                st.rerun()
            else: 
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
        st.markdown('</div>', unsafe_allow_html=True)
    return False

if not check_password(): st.stop()

# ==========================================
# 3. –ë–≠–ö–ï–ù–î (–õ–û–ì–ò–ö–ê) - –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô
# ==========================================

# --- –ü–∞—Ç—á NLP ---
try:
    if not hasattr(inspect, 'getargspec'):
        def getargspec(func):
            spec = inspect.getfullargspec(func)
            return spec.args, spec.varargs, spec.varkw, spec.defaults
        inspect.getargspec = getargspec
    import pymorphy2
    morph = pymorphy2.MorphAnalyzer()
    USE_NLP = True
except:
    morph = None
    USE_NLP = False

# --- –ü–æ–∏—Å–∫ ---
try:
    from googlesearch import search
    USE_SEARCH = True
except:
    USE_SEARCH = False

DEFAULT_EXCLUDE = ["yandex.ru", "avito.ru", "ozon.ru", "wildberries.ru", "youtube.com", "dzen.ru", "hh.ru", "t.me"]
DEFAULT_STOPS = ["—Ä—É–±–ª–µ–π", "—Ä—É–±", "–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "—à—Ç", "—Å–º", "–º–º", "–∫–≥", "–∫–≤", "–º2", "—Å—Ç—Ä", "—É–ª"]

# --- –ü–∞—Ä—Å–∏–Ω–≥ ---
def get_domain(url):
    try: return urlparse(url).netloc
    except: return url

def parse_page(url, settings):
    headers = {'User-Agent': settings['ua']}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code != 200: return None
        
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # –ú–µ—Ç–∞-—Ç–µ–≥–∏
        title = soup.title.string if soup.title else ""
        desc = ""
        meta_desc = soup.find("meta", attrs={"name": "description"})
        if meta_desc: desc = meta_desc.get("content", "")
        h1 = soup.find("h1").get_text(strip=True) if soup.find("h1") else ""
        
        # –û—á–∏—Å—Ç–∫–∞
        if settings['noindex']:
            for t in soup.find_all(['noindex', 'script', 'style']): t.decompose()
        else:
            for t in soup(['script', 'style']): t.decompose()
            
        # –ê–Ω–∫–æ—Ä—ã
        anchors_list = []
        for a in soup.find_all('a'):
            txt = a.get_text(strip=True)
            if txt: anchors_list.append(txt)
        anchor_text = " ".join(anchors_list)
        
        # –¢–µ–∫—Å—Ç (Body)
        body_text = soup.get_text(separator=' ')
        if settings['alt_title']:
            for img in soup.find_all('img', alt=True): body_text += " " + img['alt']
            
        return {
            'url': url,
            'domain': get_domain(url),
            'title': title,
            'desc': desc,
            'h1': h1,
            'body_text': body_text,
            'anchor_text': anchor_text,
            'status': 200
        }
    except:
        return None

def process_lemmas(text, settings):
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    pattern = r'[–∞-—è–ê-–Ø—ë–Å0-9a-zA-Z]+' if settings['numbers'] else r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+'
    words = re.findall(pattern, text)
    
    lemmas = []
    forms_map = {} # –ª–µ–º–º–∞ -> —Å–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º
    
    stops = set(w.lower() for w in settings['custom_stops'])
    
    for w in words:
        w_lower = w.lower()
        if len(w) < 2 or w_lower in stops: continue
        
        lemma = w_lower
        if USE_NLP:
            p = morph.parse(w_lower)[0]
            if settings['std_stops'] and ('PREP' in p.tag or 'CONJ' in p.tag or 'PRCL' in p.tag):
                continue
            lemma = p.normal_form
            
        lemmas.append(lemma)
        
        if lemma not in forms_map: forms_map[lemma] = set()
        forms_map[lemma].add(w_lower)
        
    return lemmas, forms_map

# ==========================================
# 4. –ò–ù–¢–ï–†–§–ï–ô–°: –í–í–û–î –î–ê–ù–ù–´–• (–í–°–ï–ì–î–ê –í–ò–î–ï–ù)
# ==========================================

st.title("üéØ –ì–ê–† PRO: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")

# –ì–õ–ê–í–ù–´–ô –ë–õ–û–ö –í–í–û–î–ê
with st.container():
    st.markdown('<div class="main-input-container">', unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    with c1:
        my_url = st.text_input("–í–∞—à URL (–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", placeholder="https://mysite.ru/catalog/page")
    with c2:
        query = st.text_input("–ü–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å", placeholder="–∫—É–ø–∏—Ç—å —Ç–æ–≤–∞—Ä –º–æ—Å–∫–≤–∞")
    st.markdown('</div>', unsafe_allow_html=True)

# –ò–°–¢–û–ß–ù–ò–ö –ö–û–ù–ö–£–†–ï–ù–¢–û–í
st.subheader("üìä –ò—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
source_mode = st.radio("", ["Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)", "–†—É—á–Ω–æ–π —Å–ø–∏—Å–æ–∫"], horizontal=True, label_visibility="collapsed")

competitors_final = []

if source_mode == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
    c_s1, c_s2 = st.columns([1, 3])
    with c_s1:
        top_count = st.selectbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–ü:", [5, 10, 20], index=1)
    with c_s2:
        exclude_domains = st.text_input("–ò—Å–∫–ª—é—á–∏—Ç—å –¥–æ–º–µ–Ω—ã (—á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª)", " ".join(DEFAULT_EXCLUDE))
else:
    manual_urls = st.text_area("–°–ø–∏—Å–æ–∫ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", height=150)

# –ù–ê–°–¢–†–û–ô–ö–ò (–°–ù–ò–ó–£)
with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞", expanded=True):
    col_set1, col_set2, col_set3 = st.columns(3)
    with col_set1:
        s_noindex = st.checkbox("–ò—Å–∫–ª—é—á–∞—Ç—å noindex", True)
        s_alt = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å Alt/Title", False)
    with col_set2:
        s_norm = st.checkbox("–ù–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–ª–∏–Ω–µ", True)
        s_num = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å —á–∏—Å–ª–∞", False)
    with col_set3:
        s_std_stops = st.checkbox("–£–±–∏—Ä–∞—Ç—å –ø—Ä–µ–¥–ª–æ–≥–∏", True)
    
    custom_stops_text = st.text_area("–°—Ç–æ–ø-—Å–ª–æ–≤–∞", "\n".join(DEFAULT_STOPS), height=60)
    user_agent = st.text_input("User-Agent", "Mozilla/5.0 (compatible; Hybrid-Analyzer/1.0;)")

# –ö–ù–û–ü–ö–ê –ó–ê–ü–£–°–ö–ê
if st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨ –ê–ù–ê–õ–ò–ó"):
    if not my_url:
        st.error("‚ùå –í—ã –Ω–µ –≤–≤–µ–ª–∏ URL –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞!")
        st.stop()
        
    settings = {
        'noindex': s_noindex, 'alt_title': s_alt, 'numbers': s_num,
        'norm': s_norm, 'std_stops': s_std_stops,
        'custom_stops': custom_stops_text.split(), 'ua': user_agent
    }
    
    # 1. –°–±–æ—Ä URL
    target_urls = []
    if source_mode == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
        if not query:
            st.error("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å!")
            st.stop()
        try:
            excl = exclude_domains.split()
            found = search(query, num_results=top_count*2, lang="ru")
            cnt = 0
            for u in found:
                if my_url in u: continue
                if any(x in u for x in excl): continue
                target_urls.append(u)
                cnt += 1
                if cnt >= top_count: break
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            st.stop()
    else:
        target_urls = [u.strip() for u in manual_urls.split('\n') if u.strip()]
        
    if not target_urls:
        st.error("–°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç!")
        st.stop()
        
    # 2. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    all_pages_data = []
    
    # –°–Ω–∞—á–∞–ª–∞ –º–æ–π —Å–∞–π—Ç
    with st.spinner("üîç –ê–Ω–∞–ª–∏–∑ –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞..."):
        my_page = parse_page(my_url, settings)
        if not my_page:
            st.error("‚ùå –í–∞—à —Å–∞–π—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            st.stop()
            
    # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
    progress_bar = st.progress(0)
    comp_pages = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(parse_page, u, settings): u for u in target_urls}
        done = 0
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: comp_pages.append(res)
            done += 1
            progress_bar.progress(done / len(target_urls))
            
    if len(comp_pages) < 2:
        st.error("‚ùå –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞).")
        st.stop()
        
    # ==========================================
    # 5. –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê –ò –¢–ê–ë–õ–ò–¶–´
    # ==========================================
    
    # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
    my_body_lemmas, my_body_forms = process_lemmas(my_page['body_text'], settings)
    my_anchor_lemmas, my_anchor_forms = process_lemmas(my_page['anchor_text'], settings)
    
    comp_stats = [] # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ª–µ–º–º–∞–º–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    for p in comp_pages:
        bl, _ = process_lemmas(p['body_text'], settings)
        al, _ = process_lemmas(p['anchor_text'], settings)
        comp_stats.append({'body': bl, 'anchor': al, 'len': len(bl)})
        
    # –ù–æ—Ä–º–∏—Ä–æ–≤–∫–∞
    avg_len = np.mean([c['len'] for c in comp_stats])
    my_len = len(my_body_lemmas)
    norm_k = (my_len / avg_len) if (settings['norm'] and avg_len > 0) else 1.0
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–°–ª–æ–≤–∞—Ä—å)
    vocab = set(my_body_lemmas)
    for c in comp_stats: vocab.update(c['body'])
    vocab = sorted(list(vocab))
    
    # –°–±–æ—Ä–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ)
    rows = []
    
    # –î–ª—è IDF
    N = len(comp_stats)
    doc_freqs = Counter()
    for c in comp_stats:
        for w in set(c['body']): doc_freqs[w] += 1
    
    for word in vocab:
        # –£ –º–µ–Ω—è
        my_body_tf = my_body_lemmas.count(word)
        my_anchor_tf = my_anchor_lemmas.count(word)
        
        # –£ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–º–∞—Å—Å–∏–≤—ã)
        c_body_tfs = [c['body'].count(word) for c in comp_stats]
        c_anchor_tfs = [c['anchor'].count(word) for c in comp_stats]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        median_body = np.median(c_body_tfs)
        median_anchor = np.median(c_anchor_tfs)
        max_spam = np.max(c_body_tfs)
        
        # –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏)
        target_body = int(median_body * 1.3 * norm_k)
        target_anchor = int(median_anchor * 1.3 * norm_k)
        
        diff_body = target_body - my_body_tf
        diff_anchor = target_anchor - my_anchor_tf
        
        # IDF
        df = doc_freqs[word]
        idf = math.log((N / (df if df>0 else 1)) + 1)
        
        # –§–∏–ª—å—Ç—Ä –º—É—Å–æ—Ä–∞ (–µ—Å–ª–∏ —Å–ª–æ–≤–æ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —É –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ–∑–Ω–∞—á–∏–º–æ)
        if (median_body > 0.5 or my_body_tf > 0):
            # –°–±–æ—Ä —Å–ª–æ–≤–æ—Ñ–æ—Ä–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            forms = []
            if word in my_body_forms: forms.extend(my_body_forms[word])
            # (–≤ –∏–¥–µ–∞–ª–µ –Ω—É–∂–Ω–æ —Å–æ–±–∏—Ä–∞—Ç—å —Ñ–æ—Ä–º—ã –∏ —Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, –Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–∫–∞ —Ç–∞–∫)
            forms_str = ", ".join(list(set(forms))[:3])
            
            rows.append({
                "–°–ª–æ–≤–æ": word,
                "–°–ª–æ–≤–æ—Ñ–æ—Ä–º—ã": forms_str,
                "–ü–æ–≤—Ç–æ—Ä—ã —É –≤–∞—Å": my_body_tf,
                # "–ú–∏–Ω–∏–º—É–º": np.min(c_body_tfs), # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—Å–ª–∏ –Ω–∞–¥–æ
                # "–ú–∞–∫—Å–∏–º—É–º": max_spam,
                "–û–±—â–µ–µ –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                
                "–¢–µ–≥ A —É –≤–∞—Å": my_anchor_tf,
                "–¢–µ–≥ A —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_anchor,
                "–¢–µ–≥ A –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_anchor,
                
                "–¢–µ–∫—Å—Ç —É –≤–∞—Å": my_body_tf, # –î–ª—è Body
                "–¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_body,
                "–¢–µ–∫—Å—Ç –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                
                "–ü–µ—Ä–µ—Å–ø–∞–º": int(max_spam * norm_k),
                "–ü–µ—Ä–µ—Å–ø–∞–º*IDF": round(max_spam * norm_k * idf, 1),
                
                "diff_abs": abs(diff_body) # –°–∫—Ä—ã—Ç–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            })
            
    df_main = pd.DataFrame(rows)
    
    # --- –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
    
    st.divider()
    
    # 1. –¢–ê–ë–õ–ò–¶–ê: –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ì–õ–£–ë–ò–ù–ï (Main Table)
    st.markdown('<div class="table-header">üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ</div>', unsafe_allow_html=True)
    if not df_main.empty:
        df_main = df_main.sort_values(by="diff_abs", ascending=False)
        
        # –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è (–ø–æ–¥—Å–≤–µ—Ç–∫–∞)
        def color_diff(val):
            if val > 0: return 'background-color: #e6fffb; color: #006d75' # –°–∏–Ω–µ-–∑–µ–ª–µ–Ω—ã–π
            if val < 0: return 'background-color: #fff2e8; color: #ad4e00' # –û—Ä–∞–Ω–∂–µ–≤—ã–π
            return ''
            
        st.dataframe(
            df_main.style.map(color_diff, subset=['–û–±—â–µ–µ –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å', '–¢–µ–≥ A –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å', '–¢–µ–∫—Å—Ç –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å']),
            column_config={"diff_abs": None}, # –°–∫—Ä—ã—Ç—å —Å–æ—Ä—Ç–∏—Ä–æ–≤–æ—á–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
            use_container_width=True,
            height=600
        )
    else:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")

    # 2. –¢–ê–ë–õ–ò–¶–ê: –ú–ï–¢–ê-–¢–ï–ì–ò
    st.markdown('<div class="table-header">üîç –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞-—Ç–µ–≥–∞–º</div>', unsafe_allow_html=True)
    meta_data = []
    # –ú–æ–π —Å–∞–π—Ç
    meta_data.append({
        "–¢–∏–ø": "–í–∞—à —Å–∞–π—Ç",
        "Title": my_page['title'],
        "Description": my_page['desc'],
        "H1": my_page['h1']
    })
    # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã (–ø–µ—Ä–≤—ã–µ 5)
    for i, p in enumerate(comp_pages[:5]):
        meta_data.append({
            "–¢–∏–ø": f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç {i+1} ({p['domain']})",
            "Title": p['title'],
            "Description": p['desc'],
            "H1": p['h1']
        })
    st.dataframe(pd.DataFrame(meta_data), use_container_width=True)

    # 3. –¢–ê–ë–õ–ò–¶–ê: –¢–û–ü –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò –î–û–ö–£–ú–ï–ù–¢–û–í
    st.markdown('<div class="table-header">üèÜ –¢–û–ü —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</div>', unsafe_allow_html=True)
    top_rows = []
    for i, p in enumerate(comp_pages):
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–∫–æ–ª-–≤–æ —Å–ª–æ–≤ –∏–∑ –æ–±—â–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è)
        p_lemmas, _ = process_lemmas(p['body_text'], settings)
        coverage = len(set(p_lemmas).intersection(vocab))
        
        top_rows.append({
            "–î–æ–º–µ–Ω": p['domain'],
            "–ü–æ–∑–∏—Ü–∏—è": i+1,
            "URL": p['url'],
            "–®–∏—Ä–∏–Ω–∞ (–û—Ö–≤–∞—Ç)": coverage,
            "–ì–ª—É–±–∏–Ω–∞ (–í—Å–µ–≥–æ —Å–ª–æ–≤)": len(p_lemmas)
        })
    st.dataframe(pd.DataFrame(top_rows), use_container_width=True)
