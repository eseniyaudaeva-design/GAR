import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from collections import Counter
import math
import inspect
import concurrent.futures

# ==========================================
# 1. –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ –ò –°–¢–ò–õ–ò
# ==========================================

st.set_page_config(
    page_title="SEO –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# –í–Ω–µ–¥—Ä—è–µ–º CSS —Å—Ç–∏–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—Ä–∏—Ñ—Ç–æ–≤ –∏–∑ –≤–∞—à–µ–≥–æ —Ñ–∞–π–ª–∞ (Inter)
st.markdown("""
    <style>
        /* –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —à—Ä–∏—Ñ—Ç–∞ Inter */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');

        /* –û—Å–Ω–æ–≤–Ω–æ–π —à—Ä–∏—Ñ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
        html, body, [class*="css"] {
            font-family: 'Inter', sans-serif;
            color: #171717;
        }
        
        /* –ó–∞–≥–æ–ª–æ–≤–∫–∏ */
        h1, h2, h3 {
            font-weight: 700;
            color: #0F172A;
        }

        /* –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
            max-width: 1200px;
        }

        /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–µ–π –≤–≤–æ–¥–∞ */
        .stTextInput > div > div > input {
            border-radius: 8px;
            border: 1px solid #E2E8F0;
            padding: 10px 12px;
            font-size: 16px;
        }
        .stTextInput > div > div > input:focus {
            border-color: #3B82F6;
            box-shadow: 0 0 0 1px #3B82F6;
        }
        
        /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π */
        .stTextArea > div > div > textarea {
            border-radius: 8px;
            border: 1px solid #E2E8F0;
        }

        /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–Ω–æ–ø–æ–∫ (–∞–∫—Ü–µ–Ω—Ç–Ω–∞—è) */
        div.stButton > button {
            background-color: #2563EB; /* –°–∏–Ω–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π */
            color: white;
            border-radius: 8px;
            padding: 0.6rem 1.2rem;
            font-weight: 600;
            border: none;
            width: 100%;
            transition: all 0.2s;
        }
        div.stButton > button:hover {
            background-color: #1D4ED8;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }

        /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü (Dataframe) */
        div[data-testid="stDataFrame"] {
            border: 1px solid #E2E8F0;
            border-radius: 8px;
            overflow: hidden;
        }

        /* –ö–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Ç—Ä–∏–∫ */
        div[data-testid="metric-container"] {
            background-color: #F8FAFC;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #F1F5F9;
        }

        /* –í–∫–ª–∞–¥–∫–∏ */
        .stTabs [data-baseweb="tab-list"] {
            gap: 24px;
        }
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            white-space: pre-wrap;
            border-radius: 4px 4px 0px 0px;
            gap: 1px;
            padding-top: 10px;
            padding-bottom: 10px;
            font-weight: 600;
        }
        
        /* –°–∫—Ä—ã—Ç–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –º–µ–Ω—é Streamlit */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        header {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. –ë–õ–û–ö –ê–í–¢–û–†–ò–ó–ê–¶–ò–ò
# ==========================================
def check_password():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –ø–∞—Ä–æ–ª—å –≤–µ—Ä–Ω—ã–π."""
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False

    if st.session_state["password_correct"]:
        return True

    # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º —Ñ–æ—Ä–º—É –≤—Ö–æ–¥–∞
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("<h2 style='text-align: center;'>üîí –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É</h2>", unsafe_allow_html=True)
        st.info("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ –∫ SEO –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—É")
        password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", label_visibility="collapsed", placeholder="–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å...")
        
        if st.button("–í–æ–π—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º—É"):
            # === –ü–ê–†–û–õ–¨ (–º–µ–Ω—è–π—Ç–µ –∑–¥–µ—Å—å) ===
            if password == "admin123":  
                st.session_state["password_correct"] = True
                st.rerun()
            else:
                st.error("‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
    return False

if not check_password():
    st.stop()

# ==========================================
# 3. –õ–û–ì–ò–ö–ê –ì–ê–† (BACKEND)
# ==========================================

# --- –ü–∞—Ç—á Pymorphy2 ---
try:
    if not hasattr(inspect, 'getargspec'):
        def getargspec(func):
            spec = inspect.getfullargspec(func)
            return spec.args, spec.varargs, spec.varkw, spec.defaults
        inspect.getargspec = getargspec
    import pymorphy2
    morph = pymorphy2.MorphAnalyzer()
    USE_NLP = True
except Exception:
    morph = None
    USE_NLP = False

# --- –ü–æ–∏—Å–∫ Google ---
try:
    from googlesearch import search
    USE_SEARCH = True
except ImportError:
    USE_SEARCH = False

# --- –°–ø–∏—Å–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
DEFAULT_EXCLUDE = ["yandex.ru", "avito.ru", "ozon.ru", "wildberries.ru", "wikipedia.org", "youtube.com", "dzen.ru", "rutube.ru", "hh.ru"]
DEFAULT_STOPS = ["—Ä—É–±–ª–µ–π", "—Ä—É–±", "–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "—à—Ç", "—Å–º", "–º–º", "–∫–≥", "–∫–≤", "–º2"]
STANDARD_STOP_WORDS = {
    '–∏', '–≤', '–Ω–∞', '—Å', '–∫', '–ø–æ', '–∑–∞', '–æ—Ç', '–¥–æ', '—ç—Ç–æ', '–º—ã', '–≤—ã', '–æ–Ω', '–æ–Ω–∞', '–æ–Ω–∏', '–∏—Ö', '–µ–µ', '–µ–≥–æ', '–º–Ω–µ',
    '—Ç–µ–±–µ', '—Å–µ–±–µ', '–¥–ª—è', '—á—Ç–æ', '–∫–∞–∫', '—Ç–∞–∫', '–Ω–æ', '–∏–ª–∏', '–∞', '—á—Ç–æ–±—ã', '–∂–µ', '–±—ã', '–¥–∞', '–Ω–µ—Ç', '—É', '–±–µ–∑', '–ø–æ–¥',
    '–Ω–∞–¥', '–ø–µ—Ä–µ–¥', '–ø—Ä–∏', '—á–µ—Ä–µ–∑', '–º–µ–∂–¥—É', '—Å—Ä–µ–¥–∏', '–ø–æ—Å–ª–µ', '–≤–º–µ—Å—Ç–æ', '–æ–∫–æ–ª–æ', '–≤–æ–∫—Ä—É–≥', '—Å–æ', '–∏–∑', '–∏–∑-–∑–∞', '–∏–∑-–ø–æ–¥'
}

# --- –§—É–Ω–∫—Ü–∏–∏ ---
def get_word_forms(lemma):
    if not USE_NLP or not morph: return lemma
    parses = morph.parse(lemma)
    if not parses: return lemma
    forms = {tag.word for tag in parses[0].lexeme}
    return ", ".join(list(forms)[:5])

def clean_text(html, settings):
    soup = BeautifulSoup(html, 'html.parser')
    
    if settings['noindex']:
        for tag in soup.find_all(['noindex', 'script', 'style', 'head', 'footer', 'nav', 'header', 'aside']):
            tag.decompose()
    else:
        for tag in soup(['script', 'style', 'head']):
            tag.decompose()
            
    text = soup.get_text(separator=' ')
    
    if settings['alt_title']:
        for img in soup.find_all('img', alt=True):
            text += " " + img['alt']
        for t in soup.find_all(title=True):
            text += " " + t['title']
            
    pattern = r'[–∞-—è–ê-–Ø—ë–Å0-9a-zA-Z]+' if settings['numbers'] else r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+'
    words = re.findall(pattern, text)
    
    clean_words = []
    custom_stop_list = set(w.lower() for w in settings['custom_stops'])
    
    for w in words:
        w_lower = w.lower()
        if len(w) < 2 or w_lower in custom_stop_list: continue
        
        if USE_NLP:
            p = morph.parse(w_lower)[0]
            if settings['std_stops']:
                if 'PREP' in p.tag or 'CONJ' in p.tag or 'PRCL' in p.tag:
                    continue
            clean_words.append(p.normal_form)
        else:
            clean_words.append(w_lower)
            
    return " ".join(clean_words)

def get_page(url, settings):
    headers = {'User-Agent': settings['ua']}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            return clean_text(r.text, settings)
    except:
        return ""
    return ""

def run_analysis(my_url, competitors, settings):
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã UI
    status_container = st.empty()
    progress_bar = st.progress(0)
    
    status_container.info(f"üì• –°–∫–∞—á–∏–≤–∞–µ–º –≤–∞—à —Å–∞–π—Ç: {my_url}")
    my_text = get_page(my_url, settings)
    
    if not my_text:
        status_container.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∞—à —Å–∞–π—Ç! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL.")
        return None
        
    corpus = []
    status_container.info(f"üöÄ –ê–Ω–∞–ª–∏–∑ {len(competitors)} –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_url = {executor.submit(get_page, url, settings): url for url in competitors}
        completed = 0
        for future in concurrent.futures.as_completed(future_to_url):
            txt = future.result()
            if len(txt) > 50:
                corpus.append(txt)
            completed += 1
            progress_bar.progress(completed / len(competitors))
            
    if len(corpus) < 2:
        status_container.error("‚ùå –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (–º–µ–Ω–µ–µ 2 –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤).")
        return None
        
    status_container.success("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã! –†–∞—Å—á–µ—Ç TF-IDF...")
    progress_bar.empty()
    
    # –†–∞—Å—á–µ—Ç—ã
    all_words = set(my_text.split())
    for doc in corpus:
        all_words.update(doc.split())
    all_words = sorted(list(all_words))
    
    def count_vec(text, vocab):
        cnt = Counter(text.split())
        return [cnt[w] for w in vocab]
    
    my_vec = np.array(count_vec(my_text, all_words))
    comp_vecs = np.array([count_vec(doc, all_words) for doc in corpus])
    
    medians = np.median(comp_vecs, axis=0)
    
    data = []
    norm = len(my_text.split()) / np.mean([len(d.split()) for d in corpus]) if settings['norm'] else 1.0
    
    for i, word in enumerate(all_words):
        med = medians[i]
        my_val = my_vec[i]
        
        target = int(med * 1.3 * norm) # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 1.3
        diff = target - my_val
        
        if (med > 0 or my_val > 0):
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—ã–≤–æ–¥–∞
            rec_text = "‚úÖ OK"
            if diff > 0: rec_text = f"‚ûï –î–æ–±–∞–≤–∏—Ç—å {diff}"
            elif diff < 0: rec_text = f"‚ûñ –£–±—Ä–∞—Ç—å {abs(diff)}"
            
            # –§–∏–ª—å—Ç—Ä "–º—É—Å–æ—Ä–∞"
            if med >= 0.5 or my_val >= 1:
                data.append({
                    "–°–ª–æ–≤–æ": word,
                    "–ú–µ–¥–∏–∞–Ω–∞ (–¢–û–ü)": round(med, 1),
                    "–ù–∞ —Å–∞–π—Ç–µ": int(my_val),
                    "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": rec_text,
                    "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞": abs(diff) # –°–∫—Ä—ã—Ç–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                })
                
    df = pd.DataFrame(data)
    if not df.empty:
        df = df.sort_values(by="–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞", ascending=False).drop(columns=["–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞"])
        return df
    return None

# ==========================================
# 4. –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# ==========================================

st.title("SEO –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")
st.markdown("TF-IDF –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¢–û–ü –≤—ã–¥–∞—á–∏")

# –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
tab1, tab2, tab3 = st.tabs(["üìã –ó–∞–¥–∞—á–∞", "üïµÔ∏è –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"])

with tab1:
    st.markdown("### –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏")
    col1, col2 = st.columns(2)
    with col1:
        my_url = st.text_input("URL –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞", placeholder="https://site.ru/page")
    with col2:
        query = st.text_input("–ü–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –∫—É–ø–∏—Ç—å –æ–∫–Ω–∞")
    
    st.info("üí° –í–≤–µ–¥–∏—Ç–µ URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª—é—á–µ–≤–æ–π –∑–∞–ø—Ä–æ—Å.")

with tab2:
    st.markdown("### –ò—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
    search_method = st.radio("–ö–∞–∫ —Å–æ–±—Ä–∞—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤?", ["Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)", "–°–≤–æ–π —Å–ø–∏—Å–æ–∫ URL"], horizontal=True)
    
    competitors_list = []
    
    if search_method == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
        col_s1, col_s2 = st.columns(2)
        with col_s1:
            top_n = st.selectbox("–ì–ª—É–±–∏–Ω–∞ –¢–û–ü–∞:", [5, 10, 15, 20], index=1)
        with col_s2:
            st.warning("‚ö†Ô∏è Google –º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç—ã–µ –∞–≤—Ç–æ-–∑–∞–ø—Ä–æ—Å—ã.")
        excludes = st.text_area("–ò—Å–∫–ª—é—á–∏—Ç—å –¥–æ–º–µ–Ω—ã (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):", "\n".join(DEFAULT_EXCLUDE), height=100)
    else:
        manual_urls = st.text_area("–°–ø–∏—Å–æ–∫ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):", height=200, placeholder="https://comp1.ru\nhttps://comp2.ru")

with tab3:
    st.markdown("### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
    
    with st.expander("–û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", expanded=True):
        col_opt1, col_opt2 = st.columns(2)
        with col_opt1:
            s_noindex = st.checkbox("–ò—Å–∫–ª—é—á–∞—Ç—å noindex", True)
            s_alt = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å Alt/Title", False)
            s_num = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å —á–∏—Å–ª–∞", False)
        with col_opt2:
            s_norm = st.checkbox("–ù–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞", True, help="–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –º–µ–¥–∏–∞–Ω—É, –µ—Å–ª–∏ –≤–∞—à —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω–µ–µ –∏–ª–∏ –∫–æ—Ä–æ—á–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –¢–û–ü—É")
            s_std_stops = st.checkbox("–£–±–∏—Ä–∞—Ç—å –ø—Ä–µ–¥–ª–æ–≥–∏/—Å–æ—é–∑—ã", True)
    
    with st.expander("–°—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ User-Agent"):
        custom_stops = st.text_area("–°–≤–æ–∏ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞:", "\n".join(DEFAULT_STOPS))
        ua = st.text_input("User-Agent –±–æ—Ç–∞:", "Mozilla/5.0 (compatible; Hybrid-Analyzer/1.0;)")

# –ù–∏–∂–Ω—è—è –ø–∞–Ω–µ–ª—å —Å –∫–Ω–æ–ø–∫–æ–π
st.divider()

if st.button("–ó–ê–ü–£–°–¢–ò–¢–¨ –ê–ù–ê–õ–ò–ó üöÄ"):
    if not my_url:
        st.error("‚ùå –í—ã –Ω–µ –≤–≤–µ–ª–∏ URL —Å–≤–æ–µ–≥–æ —Å–∞–π—Ç–∞!")
        st.stop()
        
    # –°–±–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤ —Å–ª–æ–≤–∞—Ä—å
    settings = {
        "noindex": s_noindex, "alt_title": s_alt, "numbers": s_num,
        "norm": s_norm, "std_stops": s_std_stops, "ua": ua,
        "custom_stops": custom_stops.split()
    }
    
    # –õ–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    comps = []
    if search_method == "Google –ü–æ–∏—Å–∫ (–ê–≤—Ç–æ)":
        if not query:
            st.error("‚ùå –î–ª—è –ø–æ–∏—Å–∫–∞ –Ω—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å!")
            st.stop()
        try:
            excl_list = excludes.split()
            # –ü—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å
            found = search(query, num_results=top_n*2, lang="ru")
            count = 0
            for u in found:
                if u == my_url: continue
                if any(x in u for x in excl_list): continue
                comps.append(u)
                count += 1
                if count >= top_n: break
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä—É—á–Ω–æ–π —Å–ø–∏—Å–æ–∫.")
    else:
        if manual_urls:
            comps = [u.strip() for u in manual_urls.split('\n') if u.strip()]
        
    if not comps:
        st.error("‚ùå –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç.")
    else:
        # –ó–ê–ü–£–°–ö –ë–≠–ö–ï–ù–î–ê
        df_res = run_analysis(my_url, comps, settings)
        
        if df_res is not None:
            st.markdown("### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
            
            # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
            def highlight_rec(val):
                if "–î–æ–±–∞–≤–∏—Ç—å" in str(val): return 'color: #166534; font-weight: bold; background-color: #dcfce7' # –ó–µ–ª–µ–Ω—ã–π
                if "–£–±—Ä–∞—Ç—å" in str(val): return 'color: #991b1b; font-weight: bold; background-color: #fee2e2' # –ö—Ä–∞—Å–Ω—ã–π
                return ''

            st.dataframe(
                df_res.style.map(highlight_rec, subset=['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']),
                use_container_width=True, 
                height=600
            )