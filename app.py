import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from collections import Counter
import math
import inspect
import concurrent.futures
from urllib.parse import urlparse

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==========================================
st.set_page_config(layout="wide", page_title="GAR PRO", page_icon="üìä")

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–∞–µ–º—ã—Ö –¥–æ–º–µ–Ω–æ–≤
DEFAULT_EXCLUDE_DOMAINS = [
    "yandex.ru", "avito.ru", "beru.ru", "tiu.ru", "aliexpress.com", "ebay.com",
    "auto.ru", "2gis.ru", "sravni.ru", "toshop.ru", "price.ru", "pandao.ru",
    "instagram.com", "wikipedia.org", "rambler.ru", "hh.ru", "banki.ru", 
    "regmarkets.ru", "zoon.ru", "pulscen.ru", "prodoctorov.ru", "blizko.ru", 
    "domclick.ru", "satom.ru", "quto.ru", "edadeal.ru", "cataloxy.ru", 
    "irr.ru", "onliner.by", "shop.by", "deal.by", "yell.ru", "profi.ru", 
    "irecommend.ru", "otzovik.com", "ozon.ru", "ozon.by", "market.yandex.ru", 
    "youtube.com", "gosuslugi.ru", "dzen.ru", "2gis.by"
]
DEFAULT_EXCLUDE = "\n".join(DEFAULT_EXCLUDE_DOMAINS)
DEFAULT_STOPS = "—Ä—É–±–ª–µ–π\n—Ä—É–±\n–∫—É–ø–∏—Ç—å\n—Ü–µ–Ω–∞\n—à—Ç\n—Å–º\n–º–º\n–∫–≥\n–∫–≤\n–º2\n—Å—Ç—Ä\n—É–ª"

# –°–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏
REGIONS = [
    "–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ö–∞–∑–∞–Ω—å", 
    "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", "–°–∞–º–∞—Ä–∞", "–ß–µ–ª—è–±–∏–Ω—Å–∫", "–û–º—Å–∫", "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä", 
    "–ö–∏–µ–≤ (UA)", "–ú–∏–Ω—Å–∫ (BY)", "–ê–ª–º–∞—Ç—ã (KZ)"
]

# –¶–≤–µ—Ç–∞
PRIMARY_COLOR = "#277EFF"    # –°–∏–Ω–∏–π –∞–∫—Ü–µ–Ω—Ç
PRIMARY_DARK = "#1E63C4"     # –¢–µ–º–Ω—ã–π —Å–∏–Ω–∏–π
TEXT_COLOR = "#3D4858"       # –¢–µ–º–Ω–æ-—Å–µ—Ä—ã–π (–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç)
LIGHT_BG_MAIN = "#F1F5F9"    # –°–≤–µ—Ç–ª–æ-—Å–µ—Ä—ã–π —Ñ–æ–Ω –ø–æ–ª–µ–π
BORDER_COLOR = "#E2E8F0"     # –¶–≤–µ—Ç —Ä–∞–º–∫–∏
DARK_BORDER = "#94a3b8"      # –¢–µ–º–Ω–∞—è —Ä–∞–º–∫–∞ –¥–ª—è –Ω–µ–≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
MAROON_DIVIDER = "#990000"   # –¢–µ–º–Ω–æ-–±–æ—Ä–¥–æ–≤—ã–π –¥–ª—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è

st.markdown(f"""
   <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        
        :root {{
            --primary-color: {PRIMARY_COLOR};
            --text-color: {TEXT_COLOR};
        }}
        
        html, body, [class*="stApp"], [class*="css"] {{
            font-family: 'Inter', sans-serif;
            background-color: #FFFFFF !important;
            color: {TEXT_COLOR} !important; 
        }}
        
        /* ======================================================= */
        /* –ï–î–ò–ù–´–ô –°–¢–ò–õ–¨ –î–õ–Ø –í–°–ï–• –ü–û–õ–ï–ô –í–í–û–î–ê (Input, Textarea)     */
        /* ======================================================= */
        
        /* 1. –ë–∞–∑–æ–≤—ã–π —Ñ–æ–Ω –∏ —Ä–∞–º–∫–∞ (–≤ —Å–ø–æ–∫–æ–π–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏) */
        .stTextInput input, 
        .stTextArea textarea, 
        .stSelectbox div[data-baseweb="select"] > div {{
            color: {TEXT_COLOR} !important;
            background-color: {LIGHT_BG_MAIN} !important;
            border: 1px solid {BORDER_COLOR} !important;
            border-radius: 6px;
        }}

        /* 2. –§–û–ö–£–° (–ü—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏) - –°–ò–ù–ò–ô –¶–í–ï–¢ –†–ê–ú–ö–ò */
        /* div[data-baseweb="input"]    -> –û–±—ã—á–Ω—ã–µ –ø–æ–ª—è */
        /* div[data-baseweb="textarea"] -> –ë–æ–ª—å—à–∏–µ –ø–æ–ª—è (–î–æ–º–µ–Ω—ã, –°—Ç–æ–ø-—Å–ª–æ–≤–∞) */
        /* div[data-baseweb="select"]   -> –í—ã–ø–∞–¥–∞—é—â–∏–µ —Å–ø–∏—Å–∫–∏ */
        
        div[data-baseweb="input"] > div:focus-within,
        div[data-baseweb="textarea"] > div:focus-within,
        div[data-baseweb="select"] > div:focus-within {{
            border-color: {PRIMARY_COLOR} !important;
            box-shadow: 0 0 0 1px {PRIMARY_COLOR} !important;
        }}

        /* 3. –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –æ–±–≤–æ–¥–∫—É —Å–∞–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤–Ω—É—Ç—Ä–∏, 
              —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥–≤–æ–π–Ω—ã—Ö —Ä–∞–º–æ–∫ –∏–ª–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ —Ü–≤–µ—Ç–æ–≤ */
        .stTextInput input:focus,
        .stTextArea textarea:focus {{
            outline: none !important;
            border-color: transparent !important;
            box-shadow: none !important;
        }}
        
        /* –¶–≤–µ—Ç –∫—É—Ä—Å–æ—Ä–∞ –≤–≤–æ–¥–∞ */
        input, textarea {{
            caret-color: {PRIMARY_COLOR} !important;
        }}

        /* ======================================================= */
        /* –û–°–¢–ê–õ–¨–ù–´–ï –≠–õ–ï–ú–ï–ù–¢–´ (–†–∞–¥–∏–æ, –ß–µ–∫–±–æ–∫—Å—ã, –ö–Ω–æ–ø–∫–∏)            */
        /* ======================================================= */

        /* –†–∞–¥–∏–æ-–∫–Ω–æ–ø–∫–∏ */
        div[role="radiogroup"] label div[data-baseweb="radio"] > div {{
            background-color: #FFFFFF !important;
            border: 2px solid {DARK_BORDER} !important;
        }}
        div[role="radiogroup"] label input:checked + div[data-baseweb="radio"] > div {{
            background-color: {PRIMARY_COLOR} !important;
            border-color: {PRIMARY_COLOR} !important;
        }}
        div[role="radiogroup"] label input:checked + div[data-baseweb="radio"] > div > div {{
            background-color: #FFFFFF !important;
        }}
        div[role="radiogroup"] label:has(input:checked) {{
            border-color: {PRIMARY_COLOR} !important;
        }}

        /* –ß–µ–∫–±–æ–∫—Å—ã */
        div[data-baseweb="checkbox"] > div:first-child {{
            background-color: #FFFFFF !important;
            border: 2px solid {DARK_BORDER} !important;
        }}
        div[data-baseweb="checkbox"] input:checked + div:first-child {{
            background-color: {PRIMARY_COLOR} !important;
            border-color: {PRIMARY_COLOR} !important;
        }}
        div[data-baseweb="checkbox"] input:checked + div:first-child svg {{
            fill: #FFFFFF !important;
        }}
        /* –£–±–∏—Ä–∞–µ–º –∫—Ä–∞—Å–Ω—ã–π —Ö–æ–≤–µ—Ä —É —á–µ–∫–±–æ–∫—Å–æ–≤ */
        div[data-baseweb="checkbox"]:hover > div:first-child {{
            border-color: {PRIMARY_COLOR} !important;
        }}

        /* –ö–Ω–æ–ø–∫–∞ */
        .stButton button {{
            background-image: linear-gradient(to right, {PRIMARY_COLOR}, {PRIMARY_DARK});
            color: white !important;
            border: none;
            border-radius: 6px;
            height: 50px;
        }}
        .stButton button:focus {{
            border-color: {PRIMARY_COLOR} !important;
            box-shadow: 0 0 0 1px {PRIMARY_COLOR} !important;
            color: white !important;
        }}

        /* –°–∞–π–¥–±–∞—Ä */
        .st-emotion-cache-1cpxwwu {{ width: 65% !important; }}
        div[data-testid="column"]:nth-child(2) {{
            background-color: #FFFFFF !important;
            border-left: 1px solid {BORDER_COLOR};
        }}
        
        /* –°–∫—Ä—ã–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∏ (caption) –≤ —Å–∞–π–¥–±–∞—Ä–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ */
        div[data-testid="column"]:nth-child(2) .stCaption {{
            display: none;
        }}
   </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. –õ–û–ì–ò–ö–ê (–ë–≠–ö–ï–ù–î - –í–ê–® –†–ê–ë–û–ß–ò–ô –ö–û–î)
# ==========================================

try:
    if not hasattr(inspect, 'getargspec'):
        def getargspec(func):
            spec = inspect.getfullargspec(func)
            return spec.args, spec.varargs, spec.varkw, spec.defaults
        inspect.getargspec = getargspec
    import pymorphy2
    morph = pymorphy2.MorphAnalyzer()
    USE_NLP = True
except:
    morph = None
    USE_NLP = False

try:
    from googlesearch import search
    USE_SEARCH = True
except:
    USE_SEARCH = False

def process_text(text, settings, n_gram=1):
    pattern = r'[–∞-—è–ê-–Ø—ë–Å0-9a-zA-Z]+' if settings['numbers'] else r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+'
    words = re.findall(pattern, text.lower())
    stops = set(w.lower() for w in settings['custom_stops'])
    clean_words = []
    
    for w in words:
        if len(w) < 2 or w in stops: continue
        lemma = w
        if USE_NLP and n_gram == 1: 
            p = morph.parse(w)[0]
            if 'PREP' in p.tag or 'CONJ' in p.tag or 'PRCL' in p.tag or 'NPRO' in p.tag: continue
            lemma = p.normal_form
        clean_words.append(lemma)
    
    if n_gram > 1:
        ngrams = []
        for i in range(len(clean_words) - n_gram + 1):
            phrase = " ".join(clean_words[i:i+n_gram])
            ngrams.append(phrase)
        return ngrams
    return clean_words

def parse_page(url, settings):
    headers = {'User-Agent': settings['ua']}
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code != 200: return None
        soup = BeautifulSoup(r.text, 'html.parser')
        
        if settings['noindex']:
            for t in soup.find_all(['noindex', 'script', 'style', 'head', 'footer', 'nav']): t.decompose()
        else:
            for t in soup(['script', 'style', 'head']): t.decompose()
            
        anchors_list = [a.get_text(strip=True) for a in soup.find_all('a') if a.get_text(strip=True)]
        anchor_text = " ".join(anchors_list)
        
        extra_text = []
        if settings['alt_title']:
            for img in soup.find_all('img', alt=True): extra_text.append(img['alt'])
            for t in soup.find_all(title=True): extra_text.append(t['title'])
        body_text = soup.get_text(separator=' ') + " " + " ".join(extra_text)
        
        return {
            'url': url, 'domain': urlparse(url).netloc, 
            'body_text': body_text, 'anchor_text': anchor_text
        }
    except: return None

def calculate_metrics(comp_data, my_data, settings):
    if not my_data or not my_data['body_text']:
        my_lemmas = []
        my_anchors = []
        my_len = 0
    else:
        my_lemmas = process_text(my_data['body_text'], settings)
        my_anchors = process_text(my_data['anchor_text'], settings)
        my_len = len(my_lemmas)
    
    comp_docs = []
    for p in comp_data:
        body = process_text(p['body_text'], settings)
        anchor = process_text(p['anchor_text'], settings)
        comp_docs.append({'body': body, 'anchor': anchor})
        
    if not comp_docs:
        return {"depth": pd.DataFrame(), "hybrid": pd.DataFrame(), "ngrams": pd.DataFrame(), "relevance_top": pd.DataFrame(), "my_score": {"width": 0, "depth": 0}}

    avg_len = np.mean([len(d['body']) for d in comp_docs])
    norm_k = (my_len / avg_len) if (settings['norm'] and avg_len > 0) else 1.0
    
    vocab = set(my_lemmas)
    for d in comp_docs: vocab.update(d['body'])
    vocab = sorted(list(vocab))
    
    N = len(comp_docs)
    doc_freqs = Counter()
    for d in comp_docs:
        for w in set(d['body']): doc_freqs[w] += 1
        
    k1, b = 1.2, 0.75
    table_depth, table_hybrid = [], []
    
    for word in vocab:
        df = doc_freqs[word]
        if df < 2 and word not in my_lemmas: continue 
        
        my_tf = my_lemmas.count(word)
        my_anch_tf = my_anchors.count(word)
        
        c_body_tfs = [d['body'].count(word) for d in comp_docs]
        c_anch_tfs = [d['anchor'].count(word) for d in comp_docs]
        
        med_tf = np.median(c_body_tfs)
        med_anch = np.median(c_anch_tfs)
        max_tf = np.max(c_body_tfs)
        
        idf = math.log((N - df + 0.5) / (df + 0.5) + 1)
        
        bm25_scores = []
        for i, d in enumerate(comp_docs):
            tf = c_body_tfs[i]
            dl = len(d['body'])
            score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (dl / avg_len)))
            bm25_scores.append(score)
        bm25_top = np.median(bm25_scores)
        
        bm25_my = 0
        if my_len > 0:
            bm25_my = idf * (my_tf * (k1 + 1)) / (my_tf + k1 * (1 - b + b * (my_len / avg_len)))
        
        target_body = int(med_tf * 1.3 * norm_k)
        diff_body = target_body - my_tf
        target_anch = int(med_anch * norm_k)
        diff_anch = target_anch - my_anch_tf
        
        if med_tf > 0.5 or my_tf > 0:
            table_depth.append({
                "–°–ª–æ–≤–æ": word, "–°–ª–æ–≤–æ—Ñ–æ—Ä–º—ã": word, "–ü–æ–≤—Ç–æ—Ä—ã —É –≤–∞—Å": my_tf, 
                "–ú–∏–Ω–∏–º—É–º": np.min(c_body_tfs), "–ú–∞–∫—Å–∏–º—É–º": int(max_tf * norm_k),
                "–û–±—â–µ–µ –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                "–¢–µ–≥ A —É –≤–∞—Å": my_anch_tf, "–¢–µ–≥ A —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_anch,
                "–¢–µ–≥ A –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_anch,
                "–¢–µ–∫—Å—Ç —É –≤–∞—Å": my_tf, "–¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": target_body, "–¢–µ–∫—Å—Ç –î–æ–±–∞–≤–∏—Ç—å/–£–±—Ä–∞—Ç—å": diff_body,
                "–ü–µ—Ä–µ—Å–ø–∞–º": int(max_tf * norm_k), "–ü–µ—Ä–µ—Å–ø–∞–º*IDF": round(max_tf * norm_k * idf, 1),
                "diff_abs": abs(diff_body)
            })
            table_hybrid.append({
                "–°–ª–æ–≤–æ": word, "TF-IDF –¢–û–ü": round(med_tf * idf, 2), "TF-IDF –≤–∞—à —Å–∞–π—Ç": round(my_tf * idf, 2),
                "BM25 –¢–û–ü": round(bm25_top, 2), "BM25 –≤–∞—à —Å–∞–π—Ç": round(bm25_my, 2), "IDF": round(idf, 2),
                "–ö–æ–ª-–≤–æ —Å–∞–π—Ç–æ–≤": df, "–ú–µ–¥–∏–∞–Ω–∞": round(med_tf, 1), "–ü–µ—Ä–µ—Å–ø–∞–º": max_tf,
                "–°—Ä–µ–¥–Ω–µ–µ –ø–æ –¢–û–ü—É": round(np.mean(c_body_tfs) if c_body_tfs else 0, 1), "–í–∞—à —Å–∞–π—Ç": my_tf,
                "<a> –ø–æ –¢–û–ü—É": round(med_anch, 1), "<a> –≤–∞—à —Å–∞–π—Ç": my_anch_tf
            })

    table_ngrams = []
    if comp_docs:
        my_bi = process_text(my_data['body_text'], settings, 2) if my_data and 'body_text' in my_data else []
        comp_bi = [process_text(p['body_text'], settings, 2) for p in comp_data]
        all_bi = set(my_bi)
        for c in comp_bi: all_bi.update(c)
        bi_freqs = Counter()
        for c in comp_bi:
            for b_ in set(c): bi_freqs[b_] += 1

        for bg in all_bi:
            df = bi_freqs[bg]
            if df < 2 and bg not in my_bi: continue
            my_c = my_bi.count(bg)
            comp_c = [c.count(bg) for c in comp_docs if 'body' in c]
            med_c = np.median(comp_c) if comp_c else 0
            if med_c > 0 or my_c > 0:
                table_ngrams.append({
                    "N-–≥—Ä–∞–º–º–∞": bg, "–ö–æ–ª-–≤–æ —Å–∞–π—Ç–æ–≤": df, "–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ": med_c,
                    "–°—Ä–µ–¥–Ω–µ–µ": round(np.mean(comp_c) if comp_c else 0, 1), "–ù–∞ —Å–∞–π—Ç–µ": my_c,
                    "TF-IDF": round(my_c * math.log(N/df if df>0 else 1), 3)
                })

    table_rel = []
    for i, p in enumerate(comp_data):
        p_lemmas = process_text(p['body_text'], settings)
        w = len(set(p_lemmas).intersection(vocab))
        table_rel.append({
            "–î–æ–º–µ–Ω": p['domain'], "–ü–æ–∑–∏—Ü–∏—è": i+1, "URL": p['url'],
            "–®–∏—Ä–∏–Ω–∞": w, "–ì–ª—É–±–∏–Ω–∞": len(p_lemmas)
        })
        
    return {
        "depth": pd.DataFrame(table_depth), "hybrid": pd.DataFrame(table_hybrid),
        "ngrams": pd.DataFrame(table_ngrams), "relevance_top": pd.DataFrame(table_rel),
        "my_score": {"width": len(set(my_lemmas).intersection(vocab)), "depth": len(my_lemmas)}
    }

# ==========================================
# 3. –ò–ù–¢–ï–†–§–ï–ô–° (–ú–ê–ö–ï–¢ –° –î–í–£–ú–Ø –ö–û–õ–û–ù–ö–ê–ú–ò)
# ==========================================

# --- –û–°–ù–û–í–ù–û–ô –ú–ê–ö–ï–¢: –î–í–ï –ö–û–õ–û–ù–ö–ò (65% / 35%) ---
col_main, col_sidebar = st.columns([65, 35]) 

# --- –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê (–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç) ---
with col_main:
    
    st.title("SEO –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–µ–π—Ç–∞ –¥–ª—è –∫–Ω–æ–ø–∫–∏
    if 'start_analysis_flag' not in st.session_state:
        st.session_state.start_analysis_flag = False

    # 1. URL –∏–ª–∏ –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –í–∞—à–µ–≥–æ —Å–∞–π—Ç–∞
    st.markdown("### URL –∏–ª–∏ –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –í–∞—à–µ–≥–æ —Å–∞–π—Ç–∞")
    my_input_type = st.radio(
        "–¢–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü—ã", 
        ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –≤–∞—à–µ–º —Å–∞–π—Ç–µ", "–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ —Ç–µ–∫—Å—Ç", "–ë–µ–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"], 
        horizontal=True,
        label_visibility="collapsed",
        key="my_page_source_radio"
    )

    my_url = ""
    my_page_content = ""

   # ...
    if my_input_type == "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –≤–∞—à–µ–º —Å–∞–π—Ç–µ":
        # –î–û–ë–ê–í–õ–ï–ù –Ø–í–ù–´–ô PLACEHOLDER
        my_url = st.text_input(
            "URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã", 
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: https://site.ru/catalog/tovar", 
            label_visibility="collapsed", 
            key="my_url_input"
        )
    # ...

    # 2. –ü–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å
    st.markdown("### –ü–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å")
    # –î–û–ë–ê–í–õ–ï–ù –Ø–í–ù–´–ô PLACEHOLDER
    query = st.text_input(
        "–û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å", 
        placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –∫—É–ø–∏—Ç—å –ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ –æ–∫–Ω–∞ –≤ –º–æ—Å–∫–≤–µ", 
        label_visibility="collapsed", 
        key="query_input"
    )

    # 3. –ü–æ–∏—Å–∫ –∏–ª–∏ URL —Å—Ç—Ä–∞–Ω–∏—Ü –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    st.markdown("### –ü–æ–∏—Å–∫ –∏–ª–∏ URL —Å—Ç—Ä–∞–Ω–∏—Ü –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
    source_type_new = st.radio(
        "–ò—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤", 
        ["–ü–æ–∏—Å–∫", "–°–ø–∏—Å–æ–∫ url-–∞–¥—Ä–µ—Å–æ–≤ –≤–∞—à–∏—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"], 
        horizontal=True,
        label_visibility="collapsed",
        key="competitor_source_radio"
    )
    source_type = "Google (–ê–≤—Ç–æ)" if source_type_new == "–ü–æ–∏—Å–∫" else "–†—É—á–Ω–æ–π —Å–ø–∏—Å–æ–∫" 

    # --- 4. –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã–µ —Å–ø–∏—Å–∫–∏ (–õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞) ---
    st.markdown("### –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã–µ —Å–ø–∏—Å–∫–∏")

    # –ù–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –¥–æ–º–µ–Ω—ã
    excludes = st.text_area("–ù–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –¥–æ–º–µ–Ω—ã (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", DEFAULT_EXCLUDE, height=200, key="settings_excludes")
    st.caption("–î–æ–º–µ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.")

    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
    c_stops = st.text_area("–°—Ç–æ–ø-—Å–ª–æ–≤–∞ (–∫–∞–∂–¥–æ–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", DEFAULT_STOPS, height=200, key="settings_stops")
    st.caption("–°–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –ø–µ—Ä–µ–¥ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π.")

    # 5. –ö–ù–û–ü–ö–ê –ó–ê–ü–£–°–ö–ê (–†–ê–°–ü–û–õ–û–ñ–ï–ù–ê –í–ù–ò–ó–£)
    st.markdown("---")
    if st.button("–ó–ê–ü–£–°–¢–ò–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary", use_container_width=True, key="start_analysis_btn"):
        st.session_state.start_analysis_flag = True

# --- –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê (–ù–∞—Å—Ç—Ä–æ–π–∫–∏) ---
with col_sidebar:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º st.container, —á—Ç–æ–±—ã —Å—Ç–∏–ª–∏ CSS-–∫–æ–ª–æ–Ω–æ–∫ –º–æ–≥–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
    with st.container(): 
        st.markdown("#####‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

        # --- –ë–ª–æ–∫ 1: –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (SELECTS/TEXT INPUTS) ---
        st.markdown("###### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
        
        # User-Agent
        ua = st.selectbox("User-Agent", ["Mozilla/5.0 (Windows NT 10.0; Win64; x64)", "YandexBot/3.0"], key="settings_ua")
        st.caption("–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫ –±—É–¥–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞.")
        
        # –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞
        search_engine = st.selectbox("–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞", ["Google", "–Ø–Ω–¥–µ–∫—Å", "–Ø–Ω–¥–µ–∫—Å + Google"], key="settings_search_engine")
        
        # –Ø–Ω–¥–µ–∫—Å / –†–µ–≥–∏–æ–Ω
        region = st.selectbox("–Ø–Ω–¥–µ–∫—Å / –†–µ–≥–∏–æ–Ω", REGIONS, key="settings_region")
        
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device = st.selectbox("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", ["Desktop", "Mobile"], key="settings_device")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–ü
        top_n = st.selectbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–ü", [10, 20, 30], index=1, key="settings_top_n")

        # –£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ url
        st.selectbox(
            "–£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ url", 
            ["–í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–ì–ª–∞–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"],
            key="settings_url_type"
        )

        # –£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∏–ø
        st.selectbox(
            "–£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∏–ø", 
            ["–í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ", "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ"],
            key="settings_content_type"
        )
        
        # –ë–ª–æ–∫ —Å –∑–∞–≥–ª—É—à–∫–∞–º–∏ —Å–ø–∏—Å–∫–æ–≤ —É–¥–∞–ª–µ–Ω –æ—Ç—Å—é–¥–∞, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –µ—Å—Ç—å —Å–ª–µ–≤–∞
        
        # --- –ë–ª–æ–∫ 3: –§–ª–∞–∂–∫–∏ ---
        st.markdown("###### –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª–∏")
        
        col_check1_s, col_check2_s = st.columns(2)
        with col_check1_s:
            st.checkbox("–ò—Å–∫–ª—é—á–∞—Ç—å noindex/script/style/head/footer/nav", True, key="settings_noindex")
            st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å Alt/Title", False, key="settings_alt")
            st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å —á–∏—Å–ª–∞ (0-9)", False, key="settings_numbers")
        with col_check2_s:
            st.checkbox("–ù–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–ª–∏–Ω–µ (LSA/BM25)", True, key="settings_norm")
            st.checkbox("–ò—Å–∫–ª—é—á–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã/–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã –≤ –ø–æ–∏—Å–∫–µ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ)", True, key="settings_agg")


# --- –õ–û–ì–ò–ö–ê –ó–ê–ü–£–°–ö–ê (–í–´–ü–û–õ–ù–Ø–ï–¢–°–Ø –ü–†–ò –ù–ê–ñ–ê–¢–ò–ò –ö–ù–û–ü–ö–ò) ---
if st.session_state.start_analysis_flag:
    st.session_state.start_analysis_flag = False

    # (–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–≤–æ–¥–∞ –∏ —Å–±–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫)
    if my_input_type == "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –≤–∞—à–µ–º —Å–∞–π—Ç–µ" and not st.session_state.get('my_url_input'):
        st.error("–í–≤–µ–¥–∏—Ç–µ URL!")
        st.stop()
        
    if my_input_type == "–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ —Ç–µ–∫—Å—Ç" and not st.session_state.get('my_content_input', '').strip():
        st.error("–í–≤–µ–¥–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∏–ª–∏ —Ç–µ–∫—Å—Ç!")
        st.stop()
    
    if source_type == "Google (–ê–≤—Ç–æ)" and st.session_state.settings_search_engine != "Google":
        st.warning(f"–ê–Ω–∞–ª–∏–∑ –¢–û–ü-–∞ –¥–ª—è **{st.session_state.settings_search_engine}** –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Google Search.")
        if not st.session_state.get('query_input'):
            st.error("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤!")
            st.stop()

    settings = {
        'noindex': st.session_state.settings_noindex, 
        'alt_title': st.session_state.settings_alt, 
        'numbers': st.session_state.settings_numbers,
        'norm': st.session_state.settings_norm, 
        'ua': st.session_state.settings_ua, 
        'custom_stops': st.session_state.settings_stops.split()
    }
    
    target_urls = []
    if source_type == "Google (–ê–≤—Ç–æ)":
        
        excl = [d.strip() for d in st.session_state.settings_excludes.split('\n') if d.strip()]
        if st.session_state.settings_agg: excl.extend(["avito", "ozon", "wildberries", "market", "tiu", "youtube"])
        
        try:
            with st.spinner(f"–°–±–æ—Ä –¢–û–ü–∞ {st.session_state.settings_search_engine}..."):
                if not USE_SEARCH:
                    st.error("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'googlesearch' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –¢–û–ü–∞.")
                    st.stop()

                found = search(st.session_state.query_input, num_results=st.session_state.settings_top_n * 2, lang="ru")
                cnt = 0
                for u in found:
                    if my_input_type == "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –≤–∞—à–µ–º —Å–∞–π—Ç–µ" and st.session_state.my_url_input in u: continue
                    if any(x in urlparse(u).netloc for x in excl): continue
                    target_urls.append(u)
                    cnt += 1
                    if cnt >= st.session_state.settings_top_n: break
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            st.stop()
    else: 
        # –†—É—á–Ω–æ–π —Å–ø–∏—Å–æ–∫ (–∏–∑ —Ä–∞–±–æ—á–µ–≥–æ text_area)
        manual_urls_area_run = st.text_area("–°–ø–∏—Å–æ–∫ URL (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", height=200, key="manual_urls_area_run")
        target_urls = [u.strip() for u in manual_urls_area_run.split('\n') if u.strip()]

    if not target_urls:
        st.error("–ù–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        st.stop()
        
    # --- –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –í–ê–®–ï–ì–û –°–ê–ô–¢–ê ---
    my_data = None
    if my_input_type == "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –≤–∞—à–µ–º —Å–∞–π—Ç–µ":
        prog = st.progress(0.0)
        status = st.empty()
        status.text("–°–∫–∞—á–∏–≤–∞–µ–º –≤–∞—à —Å–∞–π—Ç...")
        my_data = parse_page(st.session_state.my_url_input, settings)
        prog.progress(0.05)
        if not my_data:
            st.error("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–∞–π—Ç—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ '–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥'.")
            st.stop()
        prog.empty()
        status.empty()
    elif my_input_type == "–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ —Ç–µ–∫—Å—Ç":
        my_data = {
            'url': 'Local Content', 
            'domain': 'local.content', 
            'body_text': st.session_state.my_content_input, 
            'anchor_text': '' 
        }
    
    # --- –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ö–û–ù–ö–£–†–ï–ù–¢–û–í ---
    comp_data = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(parse_page, u, settings): u for u in target_urls}
        done = 0
        total_tasks = len(target_urls)
        prog_comp = st.progress(0)
        status_comp = st.empty()
        
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: comp_data.append(res)
            done += 1
            prog_comp.progress(done / total_tasks)
            status_comp.text(f"–°–∫–∞—á–∞–Ω–æ {done} –∏–∑ {total_tasks} –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤...")
            
    prog_comp.empty()
    status_comp.empty()
    
    if len(comp_data) < 2 and my_input_type != "–ë–µ–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã":
        st.warning(f"–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–º–µ–Ω–µ–µ 2). –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å {len(comp_data)} –¥–∞–Ω–Ω—ã–º–∏.")

    if not my_data and my_input_type != "–ë–µ–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã":
         st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
         st.stop()
         
    # --- –†–ê–°–ß–ï–¢ –ú–ï–¢–†–ò–ö –ò –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
    results = calculate_metrics(comp_data, my_data, settings)
    st.success("–ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∏–∂–µ.")
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
    with col_main:
        if my_data and len(comp_data) > 0:
            st.markdown("### 1. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ")
            df_d = results['depth']
            if not df_d.empty:
                df_d = df_d.sort_values(by="diff_abs", ascending=False)
                
                rows_per_page = 20
                total_rows = len(df_d)
                total_pages = math.ceil(total_rows / rows_per_page)
                
                if 'page_number' not in st.session_state: st.session_state.page_number = 1
                
                col_p1, col_p2, col_p3 = st.columns([1, 3, 1])
                with col_p1:
                    if st.button("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", key="prev_page_button") and st.session_state.page_number > 1:
                        st.session_state.page_number -= 1
                with col_p2:
                    st.markdown(f"<div style='text-align: center; padding-top: 10px; color: {TEXT_COLOR};'>–°—Ç—Ä–∞–Ω–∏—Ü–∞ <b>{st.session_state.page_number}</b> –∏–∑ {total_pages}</div>", unsafe_allow_html=True)
                with col_p3:
                    if st.button("–í–ø–µ—Ä–µ–¥ ‚û°Ô∏è", key="next_page_button") and st.session_state.page_number < total_pages:
                        st.session_state.page_number += 1
                            
                start_idx = (st.session_state.page_number - 1) * rows_per_page
                end_idx = start_idx + rows_per_page
                df_page = df_d.iloc[start_idx:end_idx]
                
                st.dataframe(df_page, column_config={"diff_abs": None}, use_container_width=True, height=800)
                st.download_button("–°–∫–∞—á–∞—Ç—å –í–°–Æ —Ç–∞–±–ª–∏—Ü—É (CSV)", df_d.to_csv().encode('utf-8'), "depth.csv")
                
                with st.expander("2. –ì–∏–±—Ä–∏–¥–Ω—ã–π –¢–û–ü"):
                    st.dataframe(results['hybrid'].sort_values(by="TF-IDF –¢–û–ü", ascending=False), use_container_width=True)
                    
                with st.expander("3. N-–≥—Ä–∞–º–º—ã"):
                    st.dataframe(results['ngrams'].sort_values(by="TF-IDF", ascending=False), use_container_width=True)

            
            with st.expander("4. –¢–û–ü —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"):
                st.dataframe(results['relevance_top'], use_container_width=True)

            if not my_data:
                st.warning("–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã (–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –ì–∏–±—Ä–∏–¥–Ω—ã–π –¢–û–ü, N-–≥—Ä–∞–º–º—ã) –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ –±—ã–ª –≤—ã–±—Ä–∞–Ω —Ä–µ–∂–∏–º '–ë–µ–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã' –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")




